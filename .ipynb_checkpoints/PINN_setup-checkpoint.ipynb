{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84bb71bb-05d0-482c-8a5f-882cc68134ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translated PINN class from TensorFlow 1.x to PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, layers: List[int]):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        for i in range(len(layers) - 2):\n",
    "            modules.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            modules.append(nn.Tanh())\n",
    "        modules.append(nn.Linear(layers[-2], layers[-1]))\n",
    "        self.model = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class PINN:\n",
    "    def __init__(self, x, y, t, v1, v5, layers, diff_norms, use_pde=True, device='cpu'):\n",
    "        self.device = device\n",
    "        self.use_pde = use_pde\n",
    "        self.diff_norms = diff_norms\n",
    "        self.loss_history = {'v1': [], 'v5': [], 'f1': [], 'f5': []} if use_pde else {'v1': [], 'v5': []}\n",
    "\n",
    "        # Convert data to tensors\n",
    "        self.x = torch.tensor(x, dtype=torch.float32).to(device).requires_grad_()\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).to(device).requires_grad_()\n",
    "        self.t = torch.tensor(t, dtype=torch.float32).to(device).requires_grad_()\n",
    "        self.v1_true = torch.tensor(v1, dtype=torch.float32).to(device)\n",
    "        self.v5_true = torch.tensor(v5, dtype=torch.float32).to(device)\n",
    "\n",
    "        X = torch.cat([self.x, self.y, self.t], dim=1)\n",
    "        self.lb = X.min(0).values\n",
    "        self.ub = X.max(0).values\n",
    "\n",
    "        # Networks\n",
    "        self.net_v1 = FeedForwardNN(layers).to(device)\n",
    "        self.net_v5 = FeedForwardNN(layers).to(device)\n",
    "        if use_pde:\n",
    "            self.net_v2 = FeedForwardNN(layers).to(device)\n",
    "            self.net_v3 = FeedForwardNN(layers).to(device)\n",
    "            self.net_v4 = FeedForwardNN(layers).to(device)\n",
    "\n",
    "        self.params = list(self.net_v1.parameters()) + list(self.net_v5.parameters())\n",
    "        if use_pde:\n",
    "            self.params += list(self.net_v2.parameters())\n",
    "            self.params += list(self.net_v3.parameters())\n",
    "            self.params += list(self.net_v4.parameters())\n",
    "\n",
    "        self.optimizer = optim.Adam(self.params, lr=1e-3)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        return 2.0 * (x - self.lb) / (self.ub - self.lb + 1e-6) - 1.0\n",
    "\n",
    "    def forward_net(self, net, x, y, t):\n",
    "        xyt = torch.cat([x, y, t], dim=1)\n",
    "        xyt_norm = self.normalize(xyt)\n",
    "        return net(xyt_norm)\n",
    "\n",
    "    def compute_derivative(self, f, x, order=1):\n",
    "        for _ in range(order):\n",
    "            f = grad(f, x, torch.ones_like(f), create_graph=True)[0]\n",
    "        return f\n",
    "\n",
    "    def compute_source_terms(self, x, v1, v5):\n",
    "        X_SRC = 0.5\n",
    "        SIG_SRC = 0.1\n",
    "        N_SRC_A = 1.0\n",
    "        ENER_SRC_A = 1.0\n",
    "        \n",
    "        S_n = N_SRC_A * torch.exp(-((x - X_SRC)**2) / (2.0 * SIG_SRC**2))\n",
    "        S_Ee = ENER_SRC_A * torch.exp(-((x - X_SRC)**2) / (2.0 * SIG_SRC**2))\n",
    "\n",
    "        cond1Sn = S_n[:, 0] > 0.01\n",
    "        S_n = torch.where(cond1Sn, S_n[:, 0], 0.001 * torch.ones_like(S_n[:, 0]))\n",
    "        cond1SEe = S_Ee[:, 0] > 0.01\n",
    "        S_Ee = torch.where(cond1SEe, S_Ee[:, 0], 0.001 * torch.ones_like(S_Ee[:, 0]))\n",
    "\n",
    "        cond2Sn = x[:, 0] > X_SRC\n",
    "        S_n = torch.where(cond2Sn, S_n, 0.5 * torch.ones_like(S_n))\n",
    "        cond2SEe = x[:, 0] > X_SRC\n",
    "        S_Ee = torch.where(cond2SEe, S_Ee, 0.5 * torch.ones_like(S_Ee))\n",
    "\n",
    "        cond4Sn = v1[:, 0] > 5.0\n",
    "        S_n = torch.where(cond4Sn, torch.zeros_like(S_n), S_n)\n",
    "        cond4SEe = v5[:, 0] > 1.0\n",
    "        S_Ee = torch.where(cond4SEe, torch.zeros_like(S_Ee), S_Ee)\n",
    "\n",
    "        return S_n.unsqueeze(1), S_Ee.unsqueeze(1)\n",
    "\n",
    "    def loss_function(self):\n",
    "        x, y, t = self.x, self.y, self.t\n",
    "        v1 = self.forward_net(self.net_v1, x, y, t)\n",
    "        v5 = self.forward_net(self.net_v5, x, y, t)\n",
    "\n",
    "        loss_v1 = torch.mean((v1 - self.v1_true) ** 2)\n",
    "        loss_v5 = torch.mean((v5 - self.v5_true) ** 2)\n",
    "\n",
    "        if not self.use_pde:\n",
    "            return loss_v1 + loss_v5\n",
    "\n",
    "        v2 = self.forward_net(self.net_v2, x, y, t)\n",
    "        v3 = self.forward_net(self.net_v3, x, y, t)\n",
    "        v4 = self.forward_net(self.net_v4, x, y, t)\n",
    "\n",
    "        # Derivatives\n",
    "        v1_t = self.compute_derivative(v1, t)\n",
    "        v1_x = self.compute_derivative(v1, x)\n",
    "        v1_y = self.compute_derivative(v1, y)\n",
    "        v5_t = self.compute_derivative(v5, t)\n",
    "        v5_x = self.compute_derivative(v5, x)\n",
    "        v5_y = self.compute_derivative(v5, y)\n",
    "        v2_x = self.compute_derivative(v2, x)\n",
    "        v2_y = self.compute_derivative(v2, y)\n",
    "\n",
    "        # Physics constants (placeholders for now)\n",
    "        MINOR_RADIUS = 0.22\n",
    "        TAU_T = 1.0\n",
    "        EPS_R = 1.0\n",
    "        ALPHA_D = 1.0\n",
    "        EPS_V = 1.0\n",
    "        ETA = 1.0\n",
    "        MASS_RATIO = 1.0\n",
    "\n",
    "        B = (0.22 + 0.68) / (0.68 + 0.22 + MINOR_RADIUS * x)\n",
    "        pe = v1 * v5\n",
    "        pe_y = self.compute_derivative(pe, y)\n",
    "        jp = v1 * ((TAU_T ** 0.5) * v4 - v3)\n",
    "\n",
    "        lnn = torch.log(v1 + 1e-6)\n",
    "        lnTe = torch.log(v5 + 1e-6)\n",
    "\n",
    "        lnn_xxxx = self.compute_derivative(lnn, x, 4)\n",
    "        lnn_yyyy = self.compute_derivative(lnn, y, 4)\n",
    "        lnTe_xxxx = self.compute_derivative(lnTe, x, 4)\n",
    "        lnTe_yyyy = self.compute_derivative(lnTe, y, 4)\n",
    "\n",
    "        D_lnn = -((50. / self.diff_norms['DiffX_norm']) ** 2.) * lnn_xxxx + \\\n",
    "                -((50. / self.diff_norms['DiffY_norm']) ** 2.) * lnn_yyyy\n",
    "\n",
    "        D_lnTe = -((50. / self.diff_norms['DiffX_norm']) ** 2.) * lnTe_xxxx + \\\n",
    "                 -((50. / self.diff_norms['DiffY_norm']) ** 2.) * lnTe_yyyy\n",
    "\n",
    "        S_n, S_Ee = self.compute_source_terms(x, v1, v5)\n",
    "\n",
    "        f_v1 = v1_t + (1. / B) * (v2_y * v1_x - v2_x * v1_y) - (-EPS_R * (v1 * v2_y - ALPHA_D * pe_y) + S_n + v1 * D_lnn)\n",
    "        f_v5 = v5_t + (1. / B) * (v2_y * v5_x - v2_x * v5_y) - v5 * (\n",
    "            5. * EPS_R * ALPHA_D * v5_y / 3. +\n",
    "            (2. / 3.) * (-EPS_R * (v2_y - ALPHA_D * pe_y / (v1 + 1e-6)) +\n",
    "                        (1. / (v1 + 1e-6)) * (ETA * jp * jp / (v5 * MASS_RATIO + 1e-6))) +\n",
    "            (2. / (3. * pe + 1e-6)) * S_Ee + D_lnTe)\n",
    "\n",
    "        loss_f1 = torch.mean(f_v1 ** 2)\n",
    "        loss_f5 = torch.mean(f_v5 ** 2)\n",
    "\n",
    "        return loss_v1 + loss_v5 + loss_f1 + loss_f5\n",
    "\n",
    "    def train_step(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss_function()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, x_star, y_star, t_star):\n",
    "        x_star = torch.tensor(x_star, dtype=torch.float32).to(self.device).requires_grad_(True)\n",
    "        y_star = torch.tensor(y_star, dtype=torch.float32).to(self.device).requires_grad_(True)\n",
    "        t_star = torch.tensor(t_star, dtype=torch.float32).to(self.device).requires_grad_(True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            v1 = self.forward_net(self.net_v1, x_star, y_star, t_star)\n",
    "            v5 = self.forward_net(self.net_v5, x_star, y_star, t_star)\n",
    "            result = {'v1': v1.cpu().numpy(), 'v5': v5.cpu().numpy()}\n",
    "            if self.use_pde:\n",
    "                v2 = self.forward_net(self.net_v2, x_star, y_star, t_star)\n",
    "                v3 = self.forward_net(self.net_v3, x_star, y_star, t_star)\n",
    "                v4 = self.forward_net(self.net_v4, x_star, y_star, t_star)\n",
    "                result.update({\n",
    "                    'v2': v2.cpu().numpy(),\n",
    "                    'v3': v3.cpu().numpy(),\n",
    "                    'v4': v4.cpu().numpy()\n",
    "                })\n",
    "        return result\n",
    "\n",
    "    def save(self, path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        torch.save({\n",
    "            'net_v1': self.net_v1.state_dict(),\n",
    "            'net_v5': self.net_v5.state_dict(),\n",
    "            'net_v2': self.net_v2.state_dict() if self.use_pde else None,\n",
    "            'net_v3': self.net_v3.state_dict() if self.use_pde else None,\n",
    "            'net_v4': self.net_v4.state_dict() if self.use_pde else None,\n",
    "            'diff_norms': self.diff_norms,\n",
    "            'loss_history': self.loss_history\n",
    "        }, os.path.join(path, 'checkpoint.pth'))\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(os.path.join(path, 'checkpoint.pth'))\n",
    "        self.net_v1.load_state_dict(checkpoint['net_v1'])\n",
    "        self.net_v5.load_state_dict(checkpoint['net_v5'])\n",
    "        if self.use_pde:\n",
    "            self.net_v2.load_state_dict(checkpoint['net_v2'])\n",
    "            self.net_v3.load_state_dict(checkpoint['net_v3'])\n",
    "            self.net_v4.load_state_dict(checkpoint['net_v4'])\n",
    "        self.diff_norms = checkpoint['diff_norms']\n",
    "        self.loss_history = checkpoint['loss_history']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
